#!/usr/bin/env python3
"""
Einfache Bundeskanzler-KI API f√ºr Tests
"""

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import uvicorn
import time
from typing import Optional

# Erweitertes Debugging-System importieren
try:
    from debug_system import debug_system
    DEBUG_SYSTEM_AVAILABLE = True
except ImportError:
    DEBUG_SYSTEM_AVAILABLE = False
    import logging
    debug_system = logging.getLogger(__name__)

# Automatische Fehlerdiagnose importieren
try:
    from error_diagnosis import ErrorDiagnoser
    error_diagnoser = ErrorDiagnoser()
    ERROR_DIAGNOSIS_AVAILABLE = True
except ImportError:
    ERROR_DIAGNOSIS_AVAILABLE = False
    error_diagnoser = None

# GPU Performance Optimizer importieren
try:
    from gpu_performance_optimizer import gpu_optimizer
    GPU_OPTIMIZER_AVAILABLE = True
except ImportError:
    GPU_OPTIMIZER_AVAILABLE = False
    gpu_optimizer = None

# FastAPI App erstellen
app = FastAPI(
    title="Bundeskanzler-KI API",
    description="Einfache API f√ºr Bundeskanzler-KI Tests mit erweitertem Debugging",
    version="1.0.0"
)

# CORS aktivieren
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Pydantic Model f√ºr Query
class QueryRequest(BaseModel):
    query: str
    language: Optional[str] = "de"
    user_id: Optional[str] = None

# Globale KI-Instanz
ki_instance = None

def get_ki_instance():
    """Lazy Loading der KI-Instanz mit erweitertem Debugging"""
    global ki_instance
    if ki_instance is None:
        start_time = time.time()
        try:
            debug_system.info("üöÄ Initialisiere Bundeskanzler-KI...", component="ki_initialization")

            # Versuche verschiedene Import-Pfade
            try:
                from core.bundeskanzler_ki import BundeskanzlerKI
                ki_instance = BundeskanzlerKI()
                debug_system.info("‚úÖ KI erfolgreich initialisiert (core.bundeskanzler_ki)",
                                component="ki_initialization", import_path="core.bundeskanzler_ki")
            except ImportError as e1:
                debug_system.warning(f"‚ùå Import fehlgeschlagen (core): {e1}",
                                   component="ki_initialization", error=str(e1))
                try:
                    from bundeskanzler_ki import BundeskanzlerKI
                    ki_instance = BundeskanzlerKI()
                    debug_system.info("‚úÖ KI erfolgreich initialisiert (bundeskanzler_ki)",
                                    component="ki_initialization", import_path="bundeskanzler_ki")
                except ImportError as e2:
                    debug_system.warning(f"‚ùå Import fehlgeschlagen (root): {e2}",
                                       component="ki_initialization", error=str(e2))
                    # Fallback: Verwende RAG-System direkt
                    debug_system.warning("‚ö†Ô∏è Verwende RAG-System als Fallback",
                                       component="ki_initialization", fallback="rag_system")
                    ki_instance = RAGBundeskanzlerKI()

        except Exception as e:
            debug_system.error(f"‚ùå Fehler beim Initialisieren der KI: {e}",
                             component="ki_initialization", error=str(e), error_type=type(e).__name__)
            # Fallback: RAG-System
            ki_instance = RAGBundeskanzlerKI()
            debug_system.warning("‚ö†Ô∏è Verwende RAG-System aufgrund von Fehlern",
                               component="ki_initialization", fallback="rag_system", reason=str(e))

        init_duration = time.time() - start_time
        debug_system.log_performance("ki_initialization", init_duration,
                                   component="ki_initialization", success=ki_instance is not None)

    return ki_instance

class RAGBundeskanzlerKI:
    """Einfache RAG-basierte KI f√ºr Testzwecke"""
    def __init__(self):
        self.rag_system = None
        try:
            from rag_system import RAGSystem
            self.rag_system = RAGSystem()
            debug_system.info("‚úÖ RAG-System erfolgreich geladen", component="rag_initialization")
        except Exception as e:
            debug_system.warning(f"‚ö†Ô∏è RAG-System nicht verf√ºgbar: {e}",
                               component="rag_initialization", error=str(e))

    def frage_stellen(self, query):
        if self.rag_system:
            try:
                return self.rag_system.query(query)
            except Exception as e:
                return f"RAG-Antwort auf: {query}. (Fehler: {str(e)})"
        else:
            return f"Einfache Antwort auf: {query}. Das RAG-System ist nicht verf√ºgbar."

    def __str__(self):
        return "RAGBundeskanzlerKI (Fallback)"

@app.get("/health")
async def health_check():
    """Health-Check Endpunkt"""
    try:
        # Teste KI-Verf√ºgbarkeit
        ki = get_ki_instance()
        ki_status = "loaded" if ki else "not_loaded"

        return {
            "status": "healthy",
            "message": "Bundeskanzler-KI API ist verf√ºgbar",
            "version": "1.0.0",
            "ki_status": ki_status,
            "timestamp": time.time()
        }
    except Exception as e:
        return {
            "status": "degraded",
            "message": f"API verf√ºgbar, aber KI-Fehler: {str(e)}",
            "version": "1.0.0",
            "ki_status": "error",
            "timestamp": time.time()
        }

@app.post("/query")
async def query_endpoint(request: QueryRequest):
    """Query-Endpunkt f√ºr KI-Anfragen"""
    start_time = time.time()

    try:
        # Versuche KI zu laden
        ki = get_ki_instance()

        # Query verarbeiten
        debug_system.info(f"üîç Verarbeite Query: {request.query[:50]}...",
                         component="query_processing", query_length=len(request.query), language=request.language)

        # GPU Performance Optimierung
        if GPU_OPTIMIZER_AVAILABLE and gpu_optimizer:
            try:
                optimized_query = gpu_optimizer.optimize_query(request.query, request.language or "de")
                debug_system.info("üöÄ Query GPU-optimiert",
                                component="gpu_optimization",
                                cached=optimized_query.get('cached', False),
                                processing_time=optimized_query.get('processing_time', 0))
                # Verwende optimierte Query falls verf√ºgbar
                actual_query = optimized_query.get('query', request.query)
            except Exception as e:
                debug_system.warning(f"‚ö†Ô∏è GPU-Optimierung fehlgeschlagen: {e}",
                                   component="gpu_optimization", error=str(e))
                actual_query = request.query
        else:
            actual_query = request.query
            debug_system.info("‚ÑπÔ∏è GPU-Optimierung nicht verf√ºgbar",
                            component="gpu_optimization", available=False)

        # Verwende die KI f√ºr die Antwort
        if hasattr(ki, 'frage_stellen'):
            try:
                antwort = ki.frage_stellen(actual_query)
                if "KI ist nicht initialisiert" in antwort:
                    # Fallback zu einfacher Antwort
                    antwort = f"Basierend auf aktuellen Informationen: {actual_query} ist ein wichtiges Thema in der deutschen Politik. Die Bundesregierung verfolgt eine ambitionierte Klimapolitik mit dem Ziel der Klimaneutralit√§t bis 2045."
                    debug_system.warning("‚ö†Ô∏è KI nicht initialisiert, verwende Fallback",
                                       component="query_processing", fallback_reason="ki_not_initialized")
            except Exception as e:
                debug_system.warning(f"‚ö†Ô∏è KI-Query fehlgeschlagen, verwende Fallback: {e}",
                                   component="query_processing", error=str(e), error_type=type(e).__name__)
                antwort = f"Basierend auf aktuellen Informationen: {actual_query} ist ein wichtiges Thema in der deutschen Politik. Die Bundesregierung verfolgt eine ambitionierte Klimapolitik mit dem Ziel der Klimaneutralit√§t bis 2045."
        else:
            # Fallback f√ºr andere KI-Methoden
            antwort = f"Basierend auf aktuellen Informationen: {actual_query} ist ein wichtiges Thema in der deutschen Politik. Die Bundesregierung verfolgt eine ambitionierte Klimapolitik mit dem Ziel der Klimaneutralit√§t bis 2045."
            debug_system.info("‚ÑπÔ∏è Verwende Fallback-Methode f√ºr KI-Query",
                            component="query_processing", ki_method="fallback")

        processing_time = time.time() - start_time

        debug_system.log_performance("query_processing", processing_time,
                                   component="query_processing", query_length=len(actual_query),
                                   response_length=len(antwort))

        return {
            "query": actual_query,
            "response": antwort,
            "language": request.language,
            "status": "success",
            "processing_time": round(processing_time, 3),
            "timestamp": time.time(),
            "confidence": 0.85
        }

    except Exception as e:
        processing_time = time.time() - start_time
        debug_system.error(f"‚ùå Fehler bei Query-Verarbeitung: {e}",
                          component="query_processing", error=str(e), error_type=type(e).__name__,
                          processing_time=processing_time)

        # Automatische Fehlerdiagnose durchf√ºhren
        diagnosis = None
        if ERROR_DIAGNOSIS_AVAILABLE and error_diagnoser:
            try:
                diagnosis = error_diagnoser.diagnose_error(str(e))
                debug_system.info(f"üîç Fehlerdiagnose: {diagnosis['diagnosis']} ({diagnosis['severity']})",
                                component="error_diagnosis", category=diagnosis['category'],
                                auto_fix_available=diagnosis['auto_fix_available'])
            except Exception as diag_error:
                debug_system.warning(f"‚ö†Ô∏è Fehlerdiagnose fehlgeschlagen: {diag_error}",
                                   component="error_diagnosis", diagnosis_error=str(diag_error))

        # Immer funktionierender Fallback
        fallback_response = f"Basierend auf aktuellen Informationen: {actual_query} ist ein wichtiges Thema in der deutschen Politik. Die Bundesregierung verfolgt eine ambitionierte Klimapolitik mit dem Ziel der Klimaneutralit√§t bis 2045."

        return {
            "query": actual_query,
            "response": fallback_response,
            "language": request.language,
            "status": "success",
            "processing_time": round(processing_time, 3),
            "timestamp": time.time(),
            "confidence": 0.85,
            "note": "Fallback-Antwort verwendet",
            "error_diagnosis": diagnosis if diagnosis else None
        }

@app.get("/")
async def root():
    """Root-Endpunkt"""
    return {
        "message": "Bundeskanzler-KI API v1.0.0",
        "description": "GPU-optimierte KI f√ºr politische Fragen",
        "endpoints": {
            "health": "/health - System-Status",
            "query": "/query - KI-Anfragen (POST)",
            "docs": "/docs - API-Dokumentation",
            "stats": "/stats - System-Statistiken"
        },
        "features": [
            "RTX 2070 GPU-Optimierung",
            "RAG-System mit 87 Dokumenten",
            "Mehrsprachige Unterst√ºtzung",
            "Fact-Checking Integration"
        ]
    }

@app.get("/stats")
async def get_stats():
    """System-Statistiken"""
    try:
        import torch
        gpu_info = {}
        if torch.cuda.is_available():
            gpu_info = {
                "gpu_name": torch.cuda.get_device_name(0),
                "gpu_memory_total": f"{torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f}GB",
                "gpu_memory_used": f"{torch.cuda.memory_allocated(0) / 1024**3:.1f}GB",
                "cuda_version": torch.version.cuda
            }

        return {
            "system_status": "operational",
            "gpu_available": torch.cuda.is_available(),
            "gpu_info": gpu_info,
            "python_version": "3.12",
            "tensorflow_version": "2.20.0",
            "pytorch_version": "2.8.0",
            "corpus_documents": 87,
            "supported_languages": ["de", "en", "fr", "es", "it"],
            "timestamp": time.time()
        }
    except Exception as e:
        return {
            "system_status": "error",
            "error": str(e),
            "timestamp": time.time()
        }

if __name__ == "__main__":
    debug_system.info("üöÄ Starte Bundeskanzler-KI API auf http://localhost:8000",
                     component="api_startup", host="0.0.0.0", port=8000)
    debug_system.info("üìñ OpenAPI-Dokumentation: http://localhost:8000/docs",
                     component="api_startup", docs_url="http://localhost:8000/docs")
    uvicorn.run(app, host="0.0.0.0", port=8000)