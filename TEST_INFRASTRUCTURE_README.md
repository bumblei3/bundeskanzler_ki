# Web-GUI Test-Infrastruktur

## √úbersicht

Diese Test-Infrastruktur bietet umfassende automatisierte Tests f√ºr die Bundeskanzler-KI Weboberfl√§che. Sie umfasst:

- **Automatisierte Web-GUI Tests** (`automated_web_gui_tests.py`)
- **CI/CD Test Runner** (`ci_test_runner.py`)
- **Interaktives Test-Dashboard** (`test_dashboard.py`)
- **GitHub Actions Workflow** (`.github/workflows/web-gui-tests.yml`)

## Schnellstart

### 1. Abh√§ngigkeiten installieren
```bash
pip install -r requirements.txt
```

### 2. Tests ausf√ºhren
```bash
# Alle Web-GUI Tests
make test-web-gui

# CI/CD Pipeline Tests
make test-web-gui-ci

# Vollst√§ndige Test-Suite
make test-all
```

### 3. Dashboard starten
```bash
make dashboard
```

## Test-Komponenten

### üîß Automatisierte Web-GUI Tests

**Datei:** `automated_web_gui_tests.py`

**Test-Suites:**
- **Connectivity Tests**: Verbindungspr√ºfung zu API und GUI
- **Performance Tests**: Antwortzeiten und Durchsatz
- **Functionality Tests**: Kernfunktionalit√§ten der Weboberfl√§che
- **UI/UX Tests**: Benutzeroberfl√§che und Benutzererfahrung
- **Integration Tests**: End-to-End Szenarien

**Verwendung:**
```python
from automated_web_gui_tests import WebGUITestFramework

framework = WebGUITestFramework()
results = framework.run_all_tests()
```

### üöÄ CI/CD Test Runner

**Datei:** `ci_test_runner.py`

**Features:**
- Automatische Service-Verwaltung (API + GUI)
- Umgebungs-Setup und -Cleanup
- Detaillierte Berichterstattung
- Fehlerbehandlung und Timeouts

**Verwendung:**
```bash
python ci_test_runner.py
```

### üìä Interaktives Dashboard

**Datei:** `test_dashboard.py`

**Features:**
- Live Test-Ergebnisse
- Trend-Analysen
- Suite-Vergleiche
- Detaillierte Statistiken
- Test-Ausf√ºhrung aus der GUI

**Starten:**
```bash
streamlit run test_dashboard.py
```

## GitHub Actions CI/CD

### Automatische Ausf√ºhrung

Die Tests werden automatisch ausgef√ºhrt bei:
- **Push** auf `main` oder `develop`
- **Pull Requests** zu `main` oder `develop`
- **T√§glich** um 2:00 Uhr (Scheduled)
- **Manuell** √ºber GitHub Actions

### Workflow-Konfiguration

**Datei:** `.github/workflows/web-gui-tests.yml`

**Test-Typen:**
- `all`: Alle Tests (Standard)
- `gui`: Nur GUI-Tests
- `api`: Nur API-Tests
- `performance`: Nur Performance-Tests

## Makefile Targets

```bash
# Web-GUI Tests
make test-web-gui          # Alle Web-GUI Tests
make test-web-gui-ci       # CI/CD Pipeline Tests
make test-dashboard        # Dashboard starten

# Vollst√§ndige Test-Suite
make test-all             # Alle verf√ºgbaren Tests
make test-dev             # Schnelltests f√ºr Entwicklung

# CI/CD
make ci-test              # CI/CD Pipeline ausf√ºhren
make ci-deploy            # Deployment (zuk√ºnftig)
```

## Test-Ergebnisse

### Speicherort
Test-Ergebnisse werden in `test_results/` gespeichert:
```
test_results/
‚îú‚îÄ‚îÄ web_gui_test_results_20241201_143022.json
‚îú‚îÄ‚îÄ web_gui_test_results_20241201_143500.json
‚îî‚îÄ‚îÄ ...
```

### Format
```json
{
  "connectivity_tests": {
    "total_tests": 4,
    "passed": 4,
    "failed": 0,
    "errors": 0,
    "duration": 2.34,
    "details": [...]
  },
  "performance_tests": {
    "total_tests": 6,
    "passed": 5,
    "failed": 1,
    "errors": 0,
    "duration": 15.67,
    "details": [...]
  }
}
```

## Konfiguration

### Umgebungsvariablen

```bash
# API Konfiguration
API_HOST=localhost
API_PORT=8000

# GUI Konfiguration
GUI_HOST=localhost
GUI_PORT=8502

# Test Konfiguration
TEST_TIMEOUT=30
TEST_RETRIES=3
```

### Service-Ports

- **API**: `http://localhost:8000`
- **GUI**: `http://localhost:8502`
- **Dashboard**: `http://localhost:8503`

## Fehlerbehebung

### H√§ufige Probleme

1. **Services starten nicht**
   ```bash
   # Manuell starten
   python simple_api.py &
   streamlit run modern_gui.py --server.port 8502 &
   ```

2. **Timeout-Fehler**
   - Erh√∂hen Sie `TEST_TIMEOUT` in der Konfiguration
   - √úberpr√ºfen Sie Service-Health-Endpoints

3. **Abh√§ngigkeiten fehlen**
   ```bash
   pip install -r requirements.txt
   ```

### Debug-Modus

```bash
# Ausf√ºhrliche Logs
python automated_web_gui_tests.py --verbose

# Einzelne Test-Suite
python -c "
from automated_web_gui_tests import WebGUITestFramework
framework = WebGUITestFramework()
result = framework.test_connectivity()
print(result)
"
```

## Erweiterungen

### Neue Test-Suites hinzuf√ºgen

1. **Methode zur WebGUITestFramework-Klasse hinzuf√ºgen:**
   ```python
   def test_custom_feature(self) -> TestSuiteResult:
       # Implementierung
       pass
   ```

2. **In `run_all_tests()` einbinden:**
   ```python
   results['custom_tests'] = self.test_custom_feature()
   ```

### Selenium-Integration (zuk√ºnftig)

F√ºr browserbasierte Tests kann Selenium hinzugef√ºgt werden:

```bash
pip install selenium
```

```python
from selenium import webdriver
from selenium.webdriver.chrome.options import Options

def test_browser_interaction(self):
    options = Options()
    options.add_argument("--headless")
    driver = webdriver.Chrome(options=options)
    # Test-Implementierung
```

## Monitoring und Berichterstattung

### Metriken

- **Test-Abdeckung**: Anzahl ausgef√ºhrter Tests
- **Erfolgsrate**: Prozentsatz bestandenener Tests
- **Durchschnittliche Dauer**: Test-Ausf√ºhrungszeit
- **Trend-Analyse**: Verbesserung/Verschlechterung √ºber Zeit

### Benachrichtigungen

Bei Test-Fehlern k√∂nnen Benachrichtigungen eingerichtet werden:
- Slack-Webhooks
- Email-Benachrichtigungen
- GitHub Issues erstellen

## Beitragende

### Code-Qualit√§t

- Verwenden Sie Type Hints
- Schreiben Sie Docstrings
- F√ºgen Sie Unit-Tests f√ºr neue Funktionen hinzu
- Halten Sie PEP 8 Standards ein

### Test-Richtlinien

- Tests sollten unabh√§ngig voneinander laufen
- Verwenden Sie aussagekr√§ftige Test-Namen
- Testen Sie sowohl positive als auch negative F√§lle
- Dokumentieren Sie erwartete Ergebnisse

## Lizenz

Dieses Projekt ist Teil der Bundeskanzler-KI und folgt der gleichen Lizenz.